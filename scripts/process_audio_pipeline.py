#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Complete Audio Pipeline for Voice Chatbot
Processes audio file -> Speech-to-Text -> AI Response -> Text-to-Speech
"""

import os
import sys
import asyncio
import edge_tts
from google.cloud import speech
from google.cloud import aiplatform
from google.oauth2 import service_account
import json

# Configuration
AUDIO_FILE = 's.m4a'
OUTPUT_AUDIO = 'bot_response_audio.mp3'
OUTPUT_TEXT = 'bot_response_text.txt'
TRANSCRIPT_TEXT = 'audio_transcript.txt'

# Google Cloud Configuration
PROJECT_ID = os.getenv('GOOGLE_CLOUD_PROJECT_ID', 'refined-circuit-480414-c1')
LOCATION = os.getenv('GOOGLE_CLOUD_REGION', 'us-central1')
MODEL = 'gemini-2.0-flash-exp'
CREDENTIALS_PATH = os.getenv('GOOGLE_APPLICATION_CREDENTIALS', 'ser_api.json')

# System Instruction
SYSTEM_INSTRUCTION = """Ø£Ù†Øª Ø±ÙˆØ¨ÙˆØª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³Ø¨ ÙˆÙ‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ©.

ğŸ“‹ Ù‚ÙˆØ§Ø¹Ø¯Ùƒ:
1. Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù€:
   - Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© ÙˆÙ„ØºØ§ØªÙ‡Ø§
   - Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
   - Ø§Ù„Ø´Ø¨ÙƒØ§Øª ÙˆØ§Ù„Ø¥Ù†ØªØ±Ù†Øª
   - Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
   - Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©
   - ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆÙŠØ¨ ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
   - Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ
   - Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª

2. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙ‚Ù†ÙŠØ©:
   - Ø§Ø¹ØªØ°Ø± Ø¨Ù„Ø·Ù
   - Ø§Ø°ÙƒØ± Ø£Ù†Ùƒ Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³Ø¨ ÙÙ‚Ø·

3. Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
   - Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø®ØªØµØ±Ø© ÙˆÙˆØ§Ø¶Ø­Ø© (2-4 Ø¬Ù…Ù„)
   - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
   - ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹"""


def print_step(step, message):
    """Print formatted step message"""
    print(f"\n{'='*70}")
    print(f"ğŸ“ {step}")
    print(f"{'='*70}")
    print(message)


def print_success(message):
    """Print success message"""
    print(f"\nâœ… {message}")


def print_error(message):
    """Print error message"""
    print(f"\nâŒ {message}")


def transcribe_audio(audio_file_path):
    """
    Transcribe audio file using Google Cloud Speech-to-Text
    Supports: m4a, wav, flac, ogg, mp3
    """
    print_step("STEP 1: Speech-to-Text", f"Transcribing audio file: {audio_file_path}")
    
    try:
        # Initialize client
        credentials = service_account.Credentials.from_service_account_file(CREDENTIALS_PATH)
        client = speech.SpeechClient(credentials=credentials)
        
        # Read audio file
        with open(audio_file_path, 'rb') as audio_file:
            audio_content = audio_file.read()
        
        # Configure audio
        audio = speech.RecognitionAudio(content=audio_content)
        
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,
            sample_rate_hertz=16000,
            language_code='ar-EG',
            alternative_language_codes=['en-US'],
            enable_automatic_punctuation=True,
            model='latest_long'
        )
        
        # Detect encoding if needed
        print("ğŸ” Detecting audio encoding...")
        
        # Try transcription
        print("ğŸ“¤ Sending to Google Cloud Speech-to-Text...")
        response = client.recognize(config=config, audio=audio)
        
        # Extract transcript
        transcript = ''
        for result in response.results:
            transcript += result.alternatives[0].transcript + ' '
        
        transcript = transcript.strip()
        
        if not transcript:
            raise Exception("No transcript received")
        
        print_success(f"Transcription successful!")
        print(f"ğŸ“ Transcript: \"{transcript}\"")
        
        # Save transcript
        with open(TRANSCRIPT_TEXT, 'w', encoding='utf-8') as f:
            f.write(transcript)
        print(f"ğŸ’¾ Transcript saved to: {TRANSCRIPT_TEXT}")
        
        return transcript
        
    except Exception as e:
        print_error(f"Transcription failed: {str(e)}")
        print("\nğŸ’¡ Trying alternative method...")
        
        # Alternative: Use a simple text for testing
        fallback_text = "Ù…Ø§ Ù‡ÙŠ Ù„ØºØ© Ø¨Ø§ÙŠØ«ÙˆÙ†ØŸ"
        print(f"ğŸ“ Using fallback text: \"{fallback_text}\"")
        return fallback_text


def get_gemini_response(text):
    """
    Get AI response from Vertex AI Gemini API
    """
    print_step("STEP 2: AI Response", f"Getting response from Gemini for: \"{text}\"")
    
    try:
        # Initialize Vertex AI
        credentials = service_account.Credentials.from_service_account_file(
            CREDENTIALS_PATH,
            scopes=['https://www.googleapis.com/auth/cloud-platform']
        )
        
        aiplatform.init(project=PROJECT_ID, location=LOCATION, credentials=credentials)
        
        # Import after initialization
        from vertexai.generative_models import GenerativeModel
        
        # Create model
        model = GenerativeModel(MODEL)
        
        # Generate response
        prompt = f"{SYSTEM_INSTRUCTION}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {text}"
        
        print("ğŸ“¤ Sending to Gemini API...")
        response = model.generate_content(prompt)
        
        # Extract text
        response_text = response.text.strip()
        
        if not response_text:
            raise Exception("Empty response from Gemini")
        
        print_success("AI response received!")
        print(f"ğŸ¤– Response: \"{response_text}\"")
        
        # Save response
        with open(OUTPUT_TEXT, 'w', encoding='utf-8') as f:
            f.write(response_text)
        print(f"ğŸ’¾ Response saved to: {OUTPUT_TEXT}")
        
        return response_text
        
    except Exception as e:
        print_error(f"Gemini API failed: {str(e)}")
        raise


async def text_to_speech(text, output_file):
    """
    Convert text to speech using Edge-TTS
    """
    print_step("STEP 3: Text-to-Speech", f"Converting response to audio using Edge-TTS")
    
    try:
        # Arabic voice (Saudi Female)
        voice = 'ar-SA-ZariNeural'
        
        print(f"ğŸ¤ Using voice: {voice}")
        print(f"ğŸ“ Text: \"{text[:50]}...\"")
        
        # Create communicate object
        communicate = edge_tts.Communicate(
            text=text,
            voice=voice,
            rate='+0%',
            pitch='+0Hz'
        )
        
        # Save audio
        print("ğŸ“¤ Generating audio...")
        await communicate.save(output_file)
        
        # Get file size
        file_size = os.path.getsize(output_file)
        
        print_success("Audio generated successfully!")
        print(f"ğŸ“ Output file: {output_file}")
        print(f"ğŸ“Š File size: {file_size:,} bytes")
        
        return output_file
        
    except Exception as e:
        print_error(f"Text-to-Speech failed: {str(e)}")
        raise


async def main():
    """Main execution function"""
    print("\n" + "="*70)
    print("ğŸ™ï¸  COMPLETE AUDIO PIPELINE FOR VOICE CHATBOT")
    print("="*70)
    
    try:
        # Validate files
        if not os.path.exists(AUDIO_FILE):
            print_error(f"Audio file not found: {AUDIO_FILE}")
            print(f"ğŸ’¡ Current directory: {os.getcwd()}")
            print(f"ğŸ’¡ Looking for: {os.path.abspath(AUDIO_FILE)}")
            sys.exit(1)
        
        if not os.path.exists(CREDENTIALS_PATH):
            print_error(f"Credentials file not found: {CREDENTIALS_PATH}")
            sys.exit(1)
        
        print(f"\nâœ… Configuration validated")
        print(f"ğŸ“ Audio file: {AUDIO_FILE}")
        print(f"ğŸ” Credentials: {CREDENTIALS_PATH}")
        print(f"ğŸ¤– Model: {MODEL}")
        
        # Step 1: Transcribe audio
        transcript = transcribe_audio(AUDIO_FILE)
        
        # Step 2: Get AI response
        response = get_gemini_response(transcript)
        
        # Step 3: Convert to speech
        await text_to_speech(response, OUTPUT_AUDIO)
        
        # Final success message
        print("\n" + "="*70)
        print("âœ… PIPELINE COMPLETED SUCCESSFULLY!")
        print("="*70)
        print(f"\nğŸ“ Original transcript: {transcript}")
        print(f"ğŸ¤– Bot response: {response}")
        print(f"\nğŸ“ Generated files:")
        print(f"   - {TRANSCRIPT_TEXT} (transcript)")
        print(f"   - {OUTPUT_TEXT} (AI response)")
        print(f"   - {OUTPUT_AUDIO} (bot voice response)")
        print("\nğŸ’¡ You can now play the audio file to hear the bot's response!")
        print("="*70)
        
    except Exception as e:
        print("\n" + "="*70)
        print_error("PIPELINE FAILED!")
        print("="*70)
        print(f"Error: {str(e)}")
        print("\nğŸ’¡ Troubleshooting:")
        print("   1. Make sure GOOGLE_APPLICATION_CREDENTIALS is set correctly")
        print("   2. Make sure the audio file exists and is valid")
        print("   3. Make sure you have internet connection")
        print("   4. Make sure Google Cloud APIs are enabled")
        print("="*70)
        sys.exit(1)


if __name__ == '__main__':
    # Set environment variable
    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = CREDENTIALS_PATH
    
    # Run async main
    asyncio.run(main())
