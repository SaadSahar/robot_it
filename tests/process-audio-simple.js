/**
 * ðŸŽ™ï¸ Simple Audio Pipeline for Voice Chatbot (Node.js Only)
 * 
 * This script:
 * 1. Uses a predefined question (since Speech-to-Text requires complex setup)
 * 2. Gets AI response from Vertex AI Gemini API
 * 3. Converts response to audio using available TTS methods
 * 
 * Usage: node process-audio-simple.js
 */

const fs = require('fs');
const path = require('path');
const { GoogleAuth } = require('google-auth-library');
const axios = require('axios');
const { spawn } = require('child_process');
require('dotenv').config();

// ============================================
// âš™ï¸ Configuration
// ============================================

// Use a predefined question (since we can't transcribe audio without Python)
const QUESTION = 'Ù…Ø§ Ù‡ÙŠ Ù„ØºØ© Ø¨Ø§ÙŠØ«ÙˆÙ†ØŸ';

const OUTPUT_AUDIO = path.join(__dirname, 'bot_response_audio.mp3');
const OUTPUT_TEXT = path.join(__dirname, 'bot_response_text.txt');

// Google Cloud Configuration
const PROJECT_ID = process.env.GOOGLE_CLOUD_PROJECT_ID;
const LOCATION = process.env.GOOGLE_CLOUD_REGION || 'us-central1';
const MODEL = 'gemini-2.0-flash-exp';
const CREDENTIALS_PATH = process.env.GOOGLE_APPLICATION_CREDENTIALS;

// System Instruction
const SYSTEM_INSTRUCTION = `Ø£Ù†Øª Ø±ÙˆØ¨ÙˆØª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³Ø¨ ÙˆÙ‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ©.

ðŸ“‹ Ù‚ÙˆØ§Ø¹Ø¯Ùƒ:
1. Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù€:
   - Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© ÙˆÙ„ØºØ§ØªÙ‡Ø§
   - Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
   - Ø§Ù„Ø´Ø¨ÙƒØ§Øª ÙˆØ§Ù„Ø¥Ù†ØªØ±Ù†Øª
   - Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
   - Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©
   - ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆÙŠØ¨ ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
   - Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ
   - Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª

2. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙ‚Ù†ÙŠØ©:
   - Ø§Ø¹ØªØ°Ø± Ø¨Ù„Ø·Ù
   - Ø§Ø°ÙƒØ± Ø£Ù†Ùƒ Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³Ø¨ ÙÙ‚Ø·

3. Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
   - Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø®ØªØµØ±Ø© ÙˆÙˆØ§Ø¶Ø­Ø© (2-4 Ø¬Ù…Ù„)
   - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
   - ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹`;

// ============================================
// ðŸ” Get Access Token
// ============================================

async function getAccessToken() {
    try {
        console.log('ðŸ” Getting access token from service account...');
        
        const auth = new GoogleAuth({
            keyFilename: CREDENTIALS_PATH,
            scopes: ['https://www.googleapis.com/auth/cloud-platform']
        });

        const client = await auth.getClient();
        const accessToken = await client.getAccessToken();
        
        console.log('âœ… Access token obtained');
        return accessToken.token;

    } catch (error) {
        console.error('âŒ Error getting access token:', error.message);
        throw error;
    }
}

// ============================================
// ðŸ¤– Step 1: Get AI Response
// ============================================

async function getAIResponse(question) {
    console.log('\n' + '='.repeat(70));
    console.log('ðŸ“ STEP 1: AI Response');
    console.log('='.repeat(70));
    console.log(`Question: "${question}"`);

    try {
        const accessToken = await getAccessToken();
        
        const url = `https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL}:generateContent`;

        const requestBody = {
            contents: [
                {
                    role: 'user',
                    parts: [{ text: question }]
                }
            ],
            systemInstruction: {
                parts: [{ text: SYSTEM_INSTRUCTION }]
            },
            generationConfig: {
                temperature: 0.7,
                topK: 40,
                topP: 0.95,
                maxOutputTokens: 500
            }
        };

        console.log('ðŸ“¤ Sending to Gemini API...');

        const response = await axios.post(url, requestBody, {
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${accessToken}`
            },
            timeout: 30000
        });

        // Extract response text
        const responseText = response.data?.candidates?.[0]?.content?.parts?.[0]?.text;

        if (!responseText) {
            throw new Error('No response from Gemini API');
        }

        console.log('\nâœ… AI response received!');
        console.log(`ðŸ¤– Response: "${responseText}"`);

        // Save response
        fs.writeFileSync(OUTPUT_TEXT, responseText, 'utf-8');
        console.log(`ðŸ’¾ Response saved to: ${OUTPUT_TEXT}`);

        return responseText;

    } catch (error) {
        console.error('\nâŒ Gemini API failed:', error.message);
        
        if (error.response) {
            console.error('Status:', error.response.status);
            console.error('Response:', error.response.data);
        }
        
        throw error;
    }
}

// ============================================
// ðŸ”Š Step 2: Convert to Speech (Google Cloud TTS)
// ============================================

async function convertToSpeechGoogle(text, outputFile) {
    console.log('\n' + '='.repeat(70));
    console.log('ðŸ“ STEP 2: Text-to-Speech (Google Cloud TTS)');
    console.log('='.repeat(70));
    console.log(`Converting response to audio using Google Cloud TTS`);

    try {
        const accessToken = await getAccessToken();
        
        const url = 'https://texttospeech.googleapis.com/v1/text:synthesize';

        const requestBody = {
            input: {
                text: text
            },
            voice: {
                languageCode: 'ar-EG',
                name: 'ar-EG-Wavenet-A',
                ssmlGender: 'FEMALE'
            },
            audioConfig: {
                audioEncoding: 'MP3',
                sampleRateHertz: 16000,
                speakingRate: 0.9,
                pitch: 0.0
            }
        };

        console.log('ðŸ“¤ Sending to Google Cloud TTS...');
        console.log(`ðŸŽ¤ Voice: ar-EG-Wavenet-A (Egyptian Female)`);
        console.log(`ðŸ“ Text: "${text.substring(0, 50)}..."`);

        const response = await axios.post(url, requestBody, {
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${accessToken}`
            },
            timeout: 30000,
            responseType: 'arraybuffer'
        });

        if (!response.data || response.data.byteLength === 0) {
            throw new Error('Empty audio response from TTS API');
        }

        // Save audio
        fs.writeFileSync(outputFile, response.data);
        
        const fileSize = response.data.byteLength;

        console.log('\nâœ… Audio generated successfully!');
        console.log(`ðŸ“ Output file: ${outputFile}`);
        console.log(`ðŸ“Š File size: ${fileSize.toLocaleString()} bytes`);

        return outputFile;

    } catch (error) {
        console.error('\nâŒ Google Cloud TTS failed:', error.message);
        
        if (error.response) {
            console.error('Status:', error.response.status);
            console.error('Response:', error.response.data);
        }
        
        throw error;
    }
}

// ============================================
// ðŸ”Š Alternative: Convert to Speech (Say.js)
// ============================================

async function convertToSpeechSay(text, outputFile) {
    console.log('\n' + '='.repeat(70));
    console.log('ðŸ“ STEP 2 (Alternative): Text-to-Speech (Say.js)');
    console.log('='.repeat(70));
    console.log(`Converting response to audio using Say.js`);

    return new Promise((resolve, reject) => {
        const say = require('say');
        const tempFile = path.join(__dirname, 'temp_say_output.wav');
        
        console.log(`ðŸ“ Text: "${text.substring(0, 50)}..."`);
        console.log('ðŸ“¤ Generating audio...');

        say.export(text, null, 0.75, tempFile, (err) => {
            if (err) {
                console.error('âŒ Say.js failed:', err.message);
                return reject(err);
            }

            try {
                // Read the temp file
                const audioContent = fs.readFileSync(tempFile);
                
                // Save to output file
                fs.writeFileSync(outputFile, audioContent);
                
                // Clean up temp file
                fs.unlinkSync(tempFile);

                const fileSize = audioContent.length;

                console.log('\nâœ… Audio generated successfully!');
                console.log(`ðŸ“ Output file: ${outputFile}`);
                console.log(`ðŸ“Š File size: ${fileSize.toLocaleString()} bytes`);
                console.log('\nâš ï¸ Note: Say.js uses system default voice.');
                console.log('âš ï¸ For better Arabic pronunciation, install Arabic voices in Windows or use Google Cloud TTS.');

                resolve(outputFile);

            } catch (error) {
                reject(new Error(`Failed to save audio: ${error.message}`));
            }
        });
    });
}

// ============================================
// ðŸš€ Main Execution
// ============================================

async function main() {
    console.log('\n' + '='.repeat(70));
    console.log('ðŸŽ™ï¸  VOICE CHATBOT - SIMPLE PIPELINE');
    console.log('='.repeat(70));
    console.log(`\nðŸ“ Question: ${QUESTION}`);
    console.log('ðŸ’¡ Note: Using predefined question (Speech-to-Text requires Python setup)');

    try {
        // Validate configuration
        if (!PROJECT_ID) {
            throw new Error('GOOGLE_CLOUD_PROJECT_ID not found in .env');
        }

        if (!CREDENTIALS_PATH) {
            throw new Error('GOOGLE_APPLICATION_CREDENTIALS not found in .env');
        }

        if (!fs.existsSync(CREDENTIALS_PATH)) {
            throw new Error(`Credentials file not found: ${CREDENTIALS_PATH}`);
        }

        console.log('\nâœ… Configuration validated');
        console.log(`ðŸ” Credentials: ${CREDENTIALS_PATH}`);
        console.log(`ðŸ¤– Model: ${MODEL}`);

        // Step 1: Get AI response
        const response = await getAIResponse(QUESTION);

        // Step 2: Try Google Cloud TTS first, then fallback to Say.js
        try {
            await convertToSpeechGoogle(response, OUTPUT_AUDIO);
        } catch (error) {
            console.log('\nâš ï¸ Google Cloud TTS failed, trying Say.js...');
            await convertToSpeechSay(response, OUTPUT_AUDIO);
        }

        // Final success message
        console.log('\n' + '='.repeat(70));
        console.log('âœ… PIPELINE COMPLETED SUCCESSFULLY!');
        console.log('='.repeat(70));
        console.log(`\nðŸ“ Question: ${QUESTION}`);
        console.log(`ðŸ¤– Bot response: ${response}`);
        console.log(`\nðŸ“ Generated files:`);
        console.log(`   - ${OUTPUT_TEXT} (AI response)`);
        console.log(`   - ${OUTPUT_AUDIO} (bot voice response)`);
        console.log('\nðŸ’¡ You can now play the audio file to hear the bot\'s response!');
        console.log('='.repeat(70));

    } catch (error) {
        console.log('\n' + '='.repeat(70));
        console.error('âŒ PIPELINE FAILED!');
        console.log('='.repeat(70));
        console.error(`Error: ${error.message}`);
        console.error('\nðŸ’¡ Troubleshooting:');
        console.error('   1. Make sure GOOGLE_APPLICATION_CREDENTIALS is set correctly');
        console.error('   2. Make sure you have internet connection');
        console.error('   3. Make sure Say.js is installed: npm install say');
        console.error('   4. For better Arabic TTS, enable Google Cloud Text-to-Speech API');
        console.log('='.repeat(70));
        
        process.exit(1);
    }
}

// Run the pipeline
if (require.main === module) {
    main().catch(error => {
        console.error('Fatal error:', error);
        process.exit(1);
    });
}

module.exports = {
    getAIResponse,
    convertToSpeechGoogle,
    convertToSpeechSay
};
